{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4dbdcac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e28290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e4b60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Raw Data Loading\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "display(df.head())\n",
    "\n",
    "# pixel의 수는 28(세로) * 28(가로) = 784대의 pixel\n",
    "# label이라는 column이 있는데 이 값이 바로 target(label)\n",
    "\n",
    "# 이 데이터를 학습해서 mutinormal을 수행\n",
    "# 학습데이터와 테스트 데이터를 나누어서 평가 진행\n",
    "# 모델의 정확도를 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71be8e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd2bf44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df.drop('label', axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff655c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1050/1050 [==============================] - 3s 2ms/step - loss: 1.9242 - accuracy: 0.4270 - val_loss: 1.5682 - val_accuracy: 0.6645\n",
      "Epoch 2/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 1.3610 - accuracy: 0.7233 - val_loss: 1.1929 - val_accuracy: 0.7663\n",
      "Epoch 3/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 1.0879 - accuracy: 0.7834 - val_loss: 0.9953 - val_accuracy: 0.7990\n",
      "Epoch 4/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.9344 - accuracy: 0.8086 - val_loss: 0.8751 - val_accuracy: 0.8160\n",
      "Epoch 5/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.8366 - accuracy: 0.8228 - val_loss: 0.7945 - val_accuracy: 0.8270\n",
      "Epoch 6/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.7686 - accuracy: 0.8329 - val_loss: 0.7362 - val_accuracy: 0.8361\n",
      "Epoch 7/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.7182 - accuracy: 0.8403 - val_loss: 0.6919 - val_accuracy: 0.8427\n",
      "Epoch 8/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.6792 - accuracy: 0.8460 - val_loss: 0.6570 - val_accuracy: 0.8482\n",
      "Epoch 9/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.6481 - accuracy: 0.8502 - val_loss: 0.6287 - val_accuracy: 0.8529\n",
      "Epoch 10/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.6225 - accuracy: 0.8538 - val_loss: 0.6052 - val_accuracy: 0.8556\n",
      "Epoch 11/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.6010 - accuracy: 0.8562 - val_loss: 0.5852 - val_accuracy: 0.8579\n",
      "Epoch 12/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.5827 - accuracy: 0.8587 - val_loss: 0.5681 - val_accuracy: 0.8607\n",
      "Epoch 13/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.5669 - accuracy: 0.8613 - val_loss: 0.5532 - val_accuracy: 0.8629\n",
      "Epoch 14/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.5531 - accuracy: 0.8634 - val_loss: 0.5401 - val_accuracy: 0.8639\n",
      "Epoch 15/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.5409 - accuracy: 0.8650 - val_loss: 0.5285 - val_accuracy: 0.8676\n",
      "Epoch 16/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.5300 - accuracy: 0.8665 - val_loss: 0.5181 - val_accuracy: 0.8695\n",
      "Epoch 17/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.5202 - accuracy: 0.8686 - val_loss: 0.5087 - val_accuracy: 0.8712\n",
      "Epoch 18/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.5113 - accuracy: 0.8701 - val_loss: 0.5002 - val_accuracy: 0.8727\n",
      "Epoch 19/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.5032 - accuracy: 0.8713 - val_loss: 0.4924 - val_accuracy: 0.8743\n",
      "Epoch 20/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4959 - accuracy: 0.8727 - val_loss: 0.4854 - val_accuracy: 0.8756\n",
      "Epoch 21/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4891 - accuracy: 0.8743 - val_loss: 0.4788 - val_accuracy: 0.8768\n",
      "Epoch 22/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4828 - accuracy: 0.8757 - val_loss: 0.4727 - val_accuracy: 0.8774\n",
      "Epoch 23/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4770 - accuracy: 0.8763 - val_loss: 0.4670 - val_accuracy: 0.8786\n",
      "Epoch 24/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4716 - accuracy: 0.8774 - val_loss: 0.4619 - val_accuracy: 0.8793\n",
      "Epoch 25/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4666 - accuracy: 0.8784 - val_loss: 0.4569 - val_accuracy: 0.8804\n",
      "Epoch 26/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4618 - accuracy: 0.8793 - val_loss: 0.4524 - val_accuracy: 0.8805\n",
      "Epoch 27/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4574 - accuracy: 0.8799 - val_loss: 0.4481 - val_accuracy: 0.8811\n",
      "Epoch 28/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4532 - accuracy: 0.8807 - val_loss: 0.4440 - val_accuracy: 0.8819\n",
      "Epoch 29/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4493 - accuracy: 0.8815 - val_loss: 0.4402 - val_accuracy: 0.8824\n",
      "Epoch 30/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4456 - accuracy: 0.8824 - val_loss: 0.4366 - val_accuracy: 0.8830\n",
      "Epoch 31/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4420 - accuracy: 0.8831 - val_loss: 0.4332 - val_accuracy: 0.8837\n",
      "Epoch 32/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4387 - accuracy: 0.8835 - val_loss: 0.4299 - val_accuracy: 0.8846\n",
      "Epoch 33/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4355 - accuracy: 0.8841 - val_loss: 0.4268 - val_accuracy: 0.8848\n",
      "Epoch 34/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4325 - accuracy: 0.8849 - val_loss: 0.4238 - val_accuracy: 0.8858\n",
      "Epoch 35/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4296 - accuracy: 0.8857 - val_loss: 0.4210 - val_accuracy: 0.8857\n",
      "Epoch 36/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4268 - accuracy: 0.8856 - val_loss: 0.4184 - val_accuracy: 0.8873\n",
      "Epoch 37/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4242 - accuracy: 0.8863 - val_loss: 0.4158 - val_accuracy: 0.8876\n",
      "Epoch 38/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4217 - accuracy: 0.8867 - val_loss: 0.4133 - val_accuracy: 0.8881\n",
      "Epoch 39/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4192 - accuracy: 0.8874 - val_loss: 0.4109 - val_accuracy: 0.8890\n",
      "Epoch 40/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4169 - accuracy: 0.8879 - val_loss: 0.4086 - val_accuracy: 0.8893\n",
      "Epoch 41/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4146 - accuracy: 0.8882 - val_loss: 0.4065 - val_accuracy: 0.8893\n",
      "Epoch 42/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4125 - accuracy: 0.8884 - val_loss: 0.4044 - val_accuracy: 0.8902\n",
      "Epoch 43/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4104 - accuracy: 0.8889 - val_loss: 0.4024 - val_accuracy: 0.8900\n",
      "Epoch 44/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4084 - accuracy: 0.8892 - val_loss: 0.4006 - val_accuracy: 0.8906\n",
      "Epoch 45/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4065 - accuracy: 0.8895 - val_loss: 0.3986 - val_accuracy: 0.8912\n",
      "Epoch 46/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4046 - accuracy: 0.8897 - val_loss: 0.3969 - val_accuracy: 0.8917\n",
      "Epoch 47/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4028 - accuracy: 0.8901 - val_loss: 0.3952 - val_accuracy: 0.8927\n",
      "Epoch 48/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.4010 - accuracy: 0.8905 - val_loss: 0.3934 - val_accuracy: 0.8929\n",
      "Epoch 49/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3994 - accuracy: 0.8909 - val_loss: 0.3918 - val_accuracy: 0.8930\n",
      "Epoch 50/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3977 - accuracy: 0.8913 - val_loss: 0.3902 - val_accuracy: 0.8932\n",
      "Epoch 51/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3961 - accuracy: 0.8915 - val_loss: 0.3887 - val_accuracy: 0.8937\n",
      "Epoch 52/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3946 - accuracy: 0.8918 - val_loss: 0.3871 - val_accuracy: 0.8940\n",
      "Epoch 53/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3931 - accuracy: 0.8925 - val_loss: 0.3858 - val_accuracy: 0.8942\n",
      "Epoch 54/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3916 - accuracy: 0.8928 - val_loss: 0.3844 - val_accuracy: 0.8943\n",
      "Epoch 55/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3902 - accuracy: 0.8928 - val_loss: 0.3830 - val_accuracy: 0.8942\n",
      "Epoch 56/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3888 - accuracy: 0.8933 - val_loss: 0.3817 - val_accuracy: 0.8944\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3875 - accuracy: 0.8935 - val_loss: 0.3806 - val_accuracy: 0.8946\n",
      "Epoch 58/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3861 - accuracy: 0.8941 - val_loss: 0.3792 - val_accuracy: 0.8948\n",
      "Epoch 59/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3849 - accuracy: 0.8942 - val_loss: 0.3780 - val_accuracy: 0.8951\n",
      "Epoch 60/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3836 - accuracy: 0.8946 - val_loss: 0.3768 - val_accuracy: 0.8956\n",
      "Epoch 61/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3824 - accuracy: 0.8945 - val_loss: 0.3757 - val_accuracy: 0.8956\n",
      "Epoch 62/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3813 - accuracy: 0.8953 - val_loss: 0.3746 - val_accuracy: 0.8960\n",
      "Epoch 63/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3801 - accuracy: 0.8953 - val_loss: 0.3735 - val_accuracy: 0.8962\n",
      "Epoch 64/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3790 - accuracy: 0.8958 - val_loss: 0.3725 - val_accuracy: 0.8968\n",
      "Epoch 65/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3779 - accuracy: 0.8956 - val_loss: 0.3714 - val_accuracy: 0.8971\n",
      "Epoch 66/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3768 - accuracy: 0.8961 - val_loss: 0.3704 - val_accuracy: 0.8974\n",
      "Epoch 67/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3758 - accuracy: 0.8963 - val_loss: 0.3694 - val_accuracy: 0.8975\n",
      "Epoch 68/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3747 - accuracy: 0.8966 - val_loss: 0.3685 - val_accuracy: 0.8981\n",
      "Epoch 69/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3737 - accuracy: 0.8968 - val_loss: 0.3675 - val_accuracy: 0.8981\n",
      "Epoch 70/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3727 - accuracy: 0.8969 - val_loss: 0.3666 - val_accuracy: 0.8985\n",
      "Epoch 71/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3718 - accuracy: 0.8974 - val_loss: 0.3656 - val_accuracy: 0.8985\n",
      "Epoch 72/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3709 - accuracy: 0.8976 - val_loss: 0.3648 - val_accuracy: 0.8992\n",
      "Epoch 73/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3699 - accuracy: 0.8977 - val_loss: 0.3639 - val_accuracy: 0.8990\n",
      "Epoch 74/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3690 - accuracy: 0.8980 - val_loss: 0.3631 - val_accuracy: 0.8994\n",
      "Epoch 75/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3681 - accuracy: 0.8981 - val_loss: 0.3623 - val_accuracy: 0.8994\n",
      "Epoch 76/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3673 - accuracy: 0.8985 - val_loss: 0.3615 - val_accuracy: 0.8995\n",
      "Epoch 77/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3664 - accuracy: 0.8987 - val_loss: 0.3607 - val_accuracy: 0.8996\n",
      "Epoch 78/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3656 - accuracy: 0.8990 - val_loss: 0.3600 - val_accuracy: 0.9005\n",
      "Epoch 79/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3648 - accuracy: 0.8992 - val_loss: 0.3591 - val_accuracy: 0.9005\n",
      "Epoch 80/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3640 - accuracy: 0.8994 - val_loss: 0.3584 - val_accuracy: 0.9008\n",
      "Epoch 81/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3632 - accuracy: 0.8992 - val_loss: 0.3577 - val_accuracy: 0.9007\n",
      "Epoch 82/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3624 - accuracy: 0.8996 - val_loss: 0.3570 - val_accuracy: 0.9011\n",
      "Epoch 83/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3616 - accuracy: 0.9000 - val_loss: 0.3563 - val_accuracy: 0.9010\n",
      "Epoch 84/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3609 - accuracy: 0.9000 - val_loss: 0.3557 - val_accuracy: 0.9007\n",
      "Epoch 85/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3602 - accuracy: 0.9003 - val_loss: 0.3549 - val_accuracy: 0.9010\n",
      "Epoch 86/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3594 - accuracy: 0.9002 - val_loss: 0.3542 - val_accuracy: 0.9015\n",
      "Epoch 87/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3587 - accuracy: 0.9006 - val_loss: 0.3536 - val_accuracy: 0.9018\n",
      "Epoch 88/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3580 - accuracy: 0.9009 - val_loss: 0.3530 - val_accuracy: 0.9013\n",
      "Epoch 89/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3573 - accuracy: 0.9011 - val_loss: 0.3524 - val_accuracy: 0.9015\n",
      "Epoch 90/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3567 - accuracy: 0.9008 - val_loss: 0.3518 - val_accuracy: 0.9020\n",
      "Epoch 91/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3560 - accuracy: 0.9013 - val_loss: 0.3511 - val_accuracy: 0.9021\n",
      "Epoch 92/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3554 - accuracy: 0.9014 - val_loss: 0.3506 - val_accuracy: 0.9021\n",
      "Epoch 93/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3547 - accuracy: 0.9015 - val_loss: 0.3500 - val_accuracy: 0.9025\n",
      "Epoch 94/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3541 - accuracy: 0.9016 - val_loss: 0.3494 - val_accuracy: 0.9027\n",
      "Epoch 95/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3534 - accuracy: 0.9017 - val_loss: 0.3488 - val_accuracy: 0.9030\n",
      "Epoch 96/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3528 - accuracy: 0.9018 - val_loss: 0.3482 - val_accuracy: 0.9029\n",
      "Epoch 97/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3522 - accuracy: 0.9019 - val_loss: 0.3477 - val_accuracy: 0.9031\n",
      "Epoch 98/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3516 - accuracy: 0.9021 - val_loss: 0.3472 - val_accuracy: 0.9027\n",
      "Epoch 99/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3510 - accuracy: 0.9023 - val_loss: 0.3467 - val_accuracy: 0.9035\n",
      "Epoch 100/100\n",
      "1050/1050 [==============================] - 2s 2ms/step - loss: 0.3505 - accuracy: 0.9025 - val_loss: 0.3461 - val_accuracy: 0.9032\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1221bbba280>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf                              # tensorflow 기본 import\n",
    "from tensorflow.keras.models import Sequential       # 모델 box\n",
    "from tensorflow.keras.layers import Flatten, Dense   # model안의 input layer와\n",
    "                                                       # output layer를 표현\n",
    "from tensorflow.keras.optimizers import SGD          # 알고리즘 담당\n",
    "from sklearn.model_selection import train_test_split # train, test를 분리\n",
    "from sklearn.preprocessing import MinMaxScaler        # 데이터의 정규화\n",
    "\n",
    "                                                        # 큰숫자를 작은숫자로 변경\n",
    "                                                        # 0~1사이의 실수로 변경\n",
    "\n",
    "\n",
    "# x 데이터와 t 데이터를 분리해야 해요!\n",
    "# 픽셀 데이터와 레이블 데이터를 분리해야 해요!\n",
    "# 독립변수와 종속변수를 분리해야 해요!\n",
    "x_data = df.drop('label', axis=1, inplace=False) # 2차원 형태의 pixel 데이터\n",
    "t_data = df['label'] # 1차원\n",
    "\n",
    "\n",
    "# 픽셀데이터를 정규화 (0~1사이의 실수로 변환)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data)                     # scaler를 완성시키고\n",
    "norm_x_data = scaler.transform(x_data) # scaler를 통해서 실제로 값을 변환\n",
    "\n",
    "\n",
    "# 데이터의 분할(학습용 데이터와 평가용 데이터로 분할)\n",
    "# 분할 비율은 일반적으로 7:3, 8:2 정도로 분할해요!\n",
    "# 현재 우리의 x_data => norm_x_data\n",
    "# 현재 우리의 t_data => t_data\n",
    "train_norm_x_data, test_norm_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(norm_x_data, t_data, test_size=0.3)\n",
    "\n",
    "\n",
    "model = Sequential() # model 생성\n",
    "model.add(Flatten(input_shape=(784,))) # input layer 추가\n",
    "model.add(Dense(units=10, activation='softmax')) # output layer 추가\n",
    "                                                 # activation은 확률을 알아내기 위해 각 노드가 수행하는 수학적 연산.\n",
    "\n",
    "\n",
    "# model이 어떻게 동작하는지를 지정\n",
    "model.compile(optimizer=SGD(learning_rate=0.001), loss='sparse_categorical_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 설정이 다 되었으면 모델을 학습.\n",
    "model.fit(train_norm_x_data, train_t_data, epochs=100, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617ce875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 1s 2ms/step - loss: 0.3460 - accuracy: 0.9046\n",
      "[0.3460364043712616, 0.9046111106872559]\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "print(model.evaluate(test_norm_x_data, test_t_data))\n",
    "#           loss                accuracy\n",
    "# [0.2933976948261261, 0.9191269874572754]\n",
    "# 우리 모델은 정확도가 91.9%인 모델\n",
    "# 머신러닝의 Regression 중 Logistic Regression을 여러개 결합해서 구현한 Multinomial 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea99f0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.3375 - accuracy: 0.8993 - val_loss: 0.1770 - val_accuracy: 0.9474\n",
      "Epoch 2/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.1447 - accuracy: 0.9549 - val_loss: 0.1268 - val_accuracy: 0.9592\n",
      "Epoch 3/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0979 - accuracy: 0.9700 - val_loss: 0.1188 - val_accuracy: 0.9620\n",
      "Epoch 4/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0727 - accuracy: 0.9776 - val_loss: 0.1036 - val_accuracy: 0.9683\n",
      "Epoch 5/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.1017 - val_accuracy: 0.9690\n",
      "Epoch 6/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0390 - accuracy: 0.9884 - val_loss: 0.0962 - val_accuracy: 0.9706\n",
      "Epoch 7/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0301 - accuracy: 0.9917 - val_loss: 0.0936 - val_accuracy: 0.9713\n",
      "Epoch 8/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0209 - accuracy: 0.9948 - val_loss: 0.1032 - val_accuracy: 0.9719\n",
      "Epoch 9/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0157 - accuracy: 0.9961 - val_loss: 0.0943 - val_accuracy: 0.9742\n",
      "Epoch 10/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0108 - accuracy: 0.9977 - val_loss: 0.0934 - val_accuracy: 0.9744\n",
      "Epoch 11/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0078 - accuracy: 0.9985 - val_loss: 0.0933 - val_accuracy: 0.9751\n",
      "Epoch 12/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 0.0041 - accuracy: 0.9996 - val_loss: 0.0915 - val_accuracy: 0.9767\n",
      "Epoch 13/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0952 - val_accuracy: 0.9762\n",
      "Epoch 14/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.0024 - accuracy: 0.9999 - val_loss: 0.0957 - val_accuracy: 0.9763\n",
      "Epoch 15/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9768\n",
      "Epoch 16/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9768\n",
      "Epoch 17/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9765\n",
      "Epoch 18/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0984 - val_accuracy: 0.9769\n",
      "Epoch 19/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9764\n",
      "Epoch 20/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 9.1130e-04 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9773\n",
      "Epoch 21/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 8.2931e-04 - accuracy: 1.0000 - val_loss: 0.1014 - val_accuracy: 0.9768\n",
      "Epoch 22/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 7.7336e-04 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9769\n",
      "Epoch 23/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 7.1413e-04 - accuracy: 1.0000 - val_loss: 0.1032 - val_accuracy: 0.9767\n",
      "Epoch 24/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 6.6436e-04 - accuracy: 1.0000 - val_loss: 0.1028 - val_accuracy: 0.9768\n",
      "Epoch 25/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 6.2676e-04 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9768\n",
      "Epoch 26/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 5.8542e-04 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9770\n",
      "Epoch 27/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 5.5095e-04 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9770\n",
      "Epoch 28/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 5.2298e-04 - accuracy: 1.0000 - val_loss: 0.1049 - val_accuracy: 0.9771\n",
      "Epoch 29/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 4.9372e-04 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9771\n",
      "Epoch 30/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 4.6896e-04 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9770\n",
      "Epoch 31/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 4.4595e-04 - accuracy: 1.0000 - val_loss: 0.1066 - val_accuracy: 0.9771\n",
      "Epoch 32/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 4.2700e-04 - accuracy: 1.0000 - val_loss: 0.1069 - val_accuracy: 0.9769\n",
      "Epoch 33/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 4.0813e-04 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9773\n",
      "Epoch 34/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 3.8831e-04 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9769\n",
      "Epoch 35/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 3.7293e-04 - accuracy: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9771\n",
      "Epoch 36/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 3.5778e-04 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 0.9767\n",
      "Epoch 37/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 3.4564e-04 - accuracy: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9771\n",
      "Epoch 38/100\n",
      "1050/1050 [==============================] - 6s 5ms/step - loss: 3.3153e-04 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9769\n",
      "Epoch 39/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 3.2109e-04 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9770\n",
      "Epoch 40/100\n",
      "1050/1050 [==============================] - 6s 5ms/step - loss: 3.0743e-04 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9769\n",
      "Epoch 41/100\n",
      "1050/1050 [==============================] - 5s 4ms/step - loss: 2.9850e-04 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9768\n",
      "Epoch 42/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 2.8943e-04 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9771\n",
      "Epoch 43/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 2.7865e-04 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9773\n",
      "Epoch 44/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 2.7121e-04 - accuracy: 1.0000 - val_loss: 0.1117 - val_accuracy: 0.9771\n",
      "Epoch 45/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 2.6207e-04 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9771\n",
      "Epoch 46/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 2.5434e-04 - accuracy: 1.0000 - val_loss: 0.1122 - val_accuracy: 0.9773\n",
      "Epoch 47/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 2.4772e-04 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 0.9773\n",
      "Epoch 48/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 2.4044e-04 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9770\n",
      "Epoch 49/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 2.3308e-04 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9771\n",
      "Epoch 50/100\n",
      "1050/1050 [==============================] - 6s 5ms/step - loss: 2.2725e-04 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9773\n",
      "Epoch 51/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 2.2163e-04 - accuracy: 1.0000 - val_loss: 0.1139 - val_accuracy: 0.9770\n",
      "Epoch 52/100\n",
      "1050/1050 [==============================] - 6s 5ms/step - loss: 2.1564e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9770\n",
      "Epoch 53/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 2.1016e-04 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9771\n",
      "Epoch 54/100\n",
      "1050/1050 [==============================] - 5s 5ms/step - loss: 2.0473e-04 - accuracy: 1.0000 - val_loss: 0.1146 - val_accuracy: 0.9773\n",
      "Epoch 55/100\n",
      "1050/1050 [==============================] - 6s 5ms/step - loss: 2.0039e-04 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9769\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.9550e-04 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9774\n",
      "Epoch 57/100\n",
      "1050/1050 [==============================] - 5s 5ms/step - loss: 1.9088e-04 - accuracy: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9773\n",
      "Epoch 58/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 1.8633e-04 - accuracy: 1.0000 - val_loss: 0.1158 - val_accuracy: 0.9770\n",
      "Epoch 59/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.8226e-04 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9771\n",
      "Epoch 60/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.7811e-04 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9769\n",
      "Epoch 61/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.7467e-04 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9774\n",
      "Epoch 62/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.7059e-04 - accuracy: 1.0000 - val_loss: 0.1167 - val_accuracy: 0.9769\n",
      "Epoch 63/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.6716e-04 - accuracy: 1.0000 - val_loss: 0.1165 - val_accuracy: 0.9771\n",
      "Epoch 64/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.6355e-04 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9774\n",
      "Epoch 65/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.6073e-04 - accuracy: 1.0000 - val_loss: 0.1172 - val_accuracy: 0.9771\n",
      "Epoch 66/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.5725e-04 - accuracy: 1.0000 - val_loss: 0.1173 - val_accuracy: 0.9773\n",
      "Epoch 67/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.5430e-04 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9773\n",
      "Epoch 68/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.5133e-04 - accuracy: 1.0000 - val_loss: 0.1179 - val_accuracy: 0.9771\n",
      "Epoch 69/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.4868e-04 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9773\n",
      "Epoch 70/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.4561e-04 - accuracy: 1.0000 - val_loss: 0.1182 - val_accuracy: 0.9771\n",
      "Epoch 71/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.4311e-04 - accuracy: 1.0000 - val_loss: 0.1181 - val_accuracy: 0.9775\n",
      "Epoch 72/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.4038e-04 - accuracy: 1.0000 - val_loss: 0.1186 - val_accuracy: 0.9771\n",
      "Epoch 73/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.3813e-04 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9773\n",
      "Epoch 74/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.3552e-04 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 0.9775\n",
      "Epoch 75/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.3330e-04 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9770\n",
      "Epoch 76/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 1.3105e-04 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9771\n",
      "Epoch 77/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.2882e-04 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9771\n",
      "Epoch 78/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.2674e-04 - accuracy: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9774\n",
      "Epoch 79/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.2462e-04 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9770\n",
      "Epoch 80/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.2263e-04 - accuracy: 1.0000 - val_loss: 0.1199 - val_accuracy: 0.9771\n",
      "Epoch 81/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.2058e-04 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9773\n",
      "Epoch 82/100\n",
      "1050/1050 [==============================] - 6s 5ms/step - loss: 1.1892e-04 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9769\n",
      "Epoch 83/100\n",
      "1050/1050 [==============================] - 5s 4ms/step - loss: 1.1700e-04 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9774\n",
      "Epoch 84/100\n",
      "1050/1050 [==============================] - 6s 5ms/step - loss: 1.1529e-04 - accuracy: 1.0000 - val_loss: 0.1206 - val_accuracy: 0.9775\n",
      "Epoch 85/100\n",
      "1050/1050 [==============================] - 5s 5ms/step - loss: 1.1342e-04 - accuracy: 1.0000 - val_loss: 0.1210 - val_accuracy: 0.9775\n",
      "Epoch 86/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 1.1172e-04 - accuracy: 1.0000 - val_loss: 0.1215 - val_accuracy: 0.9769\n",
      "Epoch 87/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.1014e-04 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9774\n",
      "Epoch 88/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 1.0843e-04 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9775\n",
      "Epoch 89/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 1.0710e-04 - accuracy: 1.0000 - val_loss: 0.1217 - val_accuracy: 0.9774\n",
      "Epoch 90/100\n",
      "1050/1050 [==============================] - 5s 5ms/step - loss: 1.0557e-04 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9774\n",
      "Epoch 91/100\n",
      "1050/1050 [==============================] - 5s 5ms/step - loss: 1.0386e-04 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9770\n",
      "Epoch 92/100\n",
      "1050/1050 [==============================] - 5s 5ms/step - loss: 1.0275e-04 - accuracy: 1.0000 - val_loss: 0.1221 - val_accuracy: 0.9775\n",
      "Epoch 93/100\n",
      "1050/1050 [==============================] - 5s 5ms/step - loss: 1.0128e-04 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9775\n",
      "Epoch 94/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 9.9813e-05 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9776\n",
      "Epoch 95/100\n",
      "1050/1050 [==============================] - 7s 6ms/step - loss: 9.8456e-05 - accuracy: 1.0000 - val_loss: 0.1224 - val_accuracy: 0.9774\n",
      "Epoch 96/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 9.7238e-05 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9775\n",
      "Epoch 97/100\n",
      "1050/1050 [==============================] - 5s 5ms/step - loss: 9.5985e-05 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9774\n",
      "Epoch 98/100\n",
      "1050/1050 [==============================] - 7s 7ms/step - loss: 9.4696e-05 - accuracy: 1.0000 - val_loss: 0.1228 - val_accuracy: 0.9774\n",
      "Epoch 99/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 9.3490e-05 - accuracy: 1.0000 - val_loss: 0.1232 - val_accuracy: 0.9773\n",
      "Epoch 100/100\n",
      "1050/1050 [==============================] - 6s 6ms/step - loss: 9.2330e-05 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1221d75a820>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### DNN(Deep Neural Network) MNIST 구현 ####\n",
    "import numpy as np\n",
    "import tensorflow as tf                            # tensorflow 기본 import\n",
    "from tensorflow.keras.models import Sequential     # 모델 box\n",
    "from tensorflow.keras.layers import Flatten, Dense # model안의 input layer와\n",
    "                                                    # output layer를 표현\n",
    "from tensorflow.keras.optimizers import SGD        # 알고리즘 담당\n",
    "from sklearn.model_selection import train_test_split # train, test를 분리\n",
    "from sklearn.preprocessing import MinMaxScaler       # 데이터의 정규화\n",
    "                                                      # 큰숫자를 작은숫자로 변경\n",
    "                                                      # 0~1사이의 실수로 변경\n",
    "        \n",
    "# x 데이터와 t 데이터를 분리해야 해요!\n",
    "# 픽셀 데이터와 레이블 데이터를 분리해야 해요!\n",
    "# 독립변수와 종속변수를 분리해야 해요!\n",
    "x_data = df.drop('label', axis=1, inplace=False) # 2차원 형태의 pixel 데이터\n",
    "t_data = df['label'] # 1차원\n",
    "\n",
    "# 픽셀데이터를 정규화 (0~1사이의 실수로 변환)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(x_data) # scaler를 완성시키고\n",
    "norm_x_data = scaler.transform(x_data) # scaler를 통해서 실제로 값을 변환\n",
    "\n",
    "# 데이터의 분할(학습용 데이터와 테스트 데이터로 분할)\n",
    "# 분할 비율은 일반적으로 7:3, 8:2 정도로 분할한다.\n",
    "# 현재 우리의 x_data => norm_x_data\n",
    "# 현재 우리의 t_data => t_data\n",
    "\n",
    "train_norm_x_data, test_norm_x_data, train_t_data, test_t_data = \\\n",
    "train_test_split(norm_x_data, t_data, test_size=0.3)\n",
    "\n",
    "# model 생성\n",
    "model = Sequential()\n",
    "\n",
    "# input layer 추가\n",
    "model.add(Flatten(input_shape=(784,)))\n",
    "\n",
    "# hidden layer 추가 -----------> 왜 추가?\n",
    "model.add(Dense(units=256, activation='relu'))\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "\n",
    "# output layer 추가\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "                        # activation은 확률을 알아내기 위해 각 노드가 수행하는 수학적 연산.\n",
    "\n",
    "# model이 어떻게 동작하는지를 지정\n",
    "model.compile(optimizer=SGD(learning_rate=1e-1), # 위와 달리 learning_rate가 0.1\n",
    "loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 설정이 다 되었으면 모델을 학습.\n",
    "model.fit(train_norm_x_data, \n",
    "          train_t_data, \n",
    "          epochs=100,verbose=1, \n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f370fe50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b5803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e9312",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bfb7b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9bfe0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f5c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f06c796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## 전이학습에 대해서 알아보아요!!\n",
    "## 사용하는 기학습된 네트워크(Pretrained Network)는\n",
    "## VGG16을 이용해 보아요!\n",
    "\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "model_base = VGG16(weights='imagenet',\n",
    "                    include_top=False,                      # classification 제외!\n",
    "                    input_shape=(150,150,3))\n",
    "\n",
    "model_base.trainable=False              # parameter(filter)를 동결!!\n",
    "\n",
    "print(model_base.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01f2a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageDataGenerator를 이용해서 Cats and Dogs binary classification\n",
    "# 문제를 해결해 보아요!\n",
    "# Transfer Learning을 이용해서 구현해 볼꺼예요!\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam # 평균적으로 높은 효율을 내는 알고리즘\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee8085bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Asked to retrieve element 0, but the Sequence has length 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13584\\427771224.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;31m# 설정이 다 되었으면 모델을 학습.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m model.fit(train_generator,\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    101\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    104\u001b[0m                 \u001b[1;34m\"Asked to retrieve element {idx}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m                 \u001b[1;34m\"but the Sequence \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Asked to retrieve element 0, but the Sequence has length 0"
     ]
    }
   ],
   "source": [
    "train_dir = '/content/drive/MyDrive/딥러닝비전/cat_dog_small/train'\n",
    "test_dir = '/content/drive/MyDrive/딥러닝비전/cat_dog_small/test'\n",
    "\n",
    "# ImageDataGenerator 생성\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "# ImageDataGenerator 설정\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_dir,                # 학습용 이미지를 가져올 폴더\n",
    "classes=['cats', 'dogs'], # cats 폴더의 이미지는 label을 0으로\n",
    "    \n",
    "    \n",
    "# dogs 폴더의 이미지는 label을 1로\n",
    "target_size=(150,150),            # 이미지 resize\n",
    "batch_size=20,                    # 한번에 20개의 이미지만 가져와요!\n",
    "class_mode='binary'               # 이진분류인 경우 설정\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "test_dir,                          # 평가용 이미지를 가져올 폴더\n",
    "classes=['cats', 'dogs'],          # cats 폴더의 이미지는 label을 0으로\n",
    "    \n",
    "    \n",
    "# dogs 폴더의 이미지는 label을 1로\n",
    "target_size=(150,150),             # 이미지 resize\n",
    "batch_size=20,                     # 한번에 20개의 이미지만 가져와요!\n",
    "class_mode='binary'                # 이진분류인 경우 설정\n",
    ")\n",
    "\n",
    "\n",
    "# CNN Model 구현\n",
    "model = Sequential()                # 전체 모델을 생성.\n",
    "from tensorflow.keras.applications import VGG16\n",
    "model_base = VGG16(weights='imagenet',\n",
    "include_top=False,                  # classification 제외!\n",
    "input_shape=(150,150,3))\n",
    "model_base.trainable=False          # parameter(filter)를 동결!!\n",
    "model.add(model_base)\n",
    "\n",
    "# classification하는 부분은 따로 구현해야 해요!\n",
    "# FC layer(DNN)의 input layer\n",
    "\n",
    "model.add(Flatten())                # 전체 데이터를 4차원에서 2차원으로 변경\n",
    "\n",
    "\n",
    "# hidden layer\n",
    "model.add(Dense(units=256,\n",
    "activation='relu'))\n",
    "\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(units=1,\n",
    "activation='sigmoid'))\n",
    "\n",
    "\n",
    "# print(model.summary())\n",
    "# model이 어떻게 동작하는지를 지정\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 설정이 다 되었으면 모델을 학습.\n",
    "model.fit(train_generator,\n",
    "steps_per_epoch=100,\n",
    "epochs=30,\n",
    "verbose=1,\n",
    "validation_data=test_generator,\n",
    "validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd8945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
